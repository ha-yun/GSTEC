{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "B_build_dtm_tfidf_class_5.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yun-aha/GSTEC/blob/main/B_build_dtm_tfidf_class_5_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8iUsnxOyHhD4",
        "outputId": "6671037d-d44c-4f60-8fd2-44388f383cfa"
      },
      "source": [
        "# install & import the libraries needed\n",
        "!pip3 install pandas\n",
        "!pip3 install scikit-learn\n",
        "from typing import List\n",
        "from math import log\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "# for printing out all the columns of a pandas dataframe https://towardsdatascience.com/how-to-show-all-columns-rows-of-a-pandas-dataframe-c49d4507fcf\n",
        "pd.set_option('display.max_columns', None)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from pandas) (1.19.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pg4U3QY2IB_v"
      },
      "source": [
        "# The corpus\n",
        "CORPUS = [\n",
        "    'this is the first document',\n",
        "    'the first document is this',\n",
        "    'this is the second document',\n",
        "    'and this is the third document',\n",
        "    'is this the first document'\n",
        "]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ2uAyiBIGbD"
      },
      "source": [
        "# we will reuse the functions we completed in the previous tutorial\n",
        "def tf(term: str, doc: str) -> int:\n",
        "    # typing을 하는 이유: 오류를 미연에 방지하기 위해서 (단, IDE를 사용하는 경우에만)\n",
        "    # 더 정확한 버전 (is가 this에 포함 문제가 되므로)\n",
        "    tf = sum([\n",
        "      word == term     \n",
        "      for word in doc.split(\" \")  # word count\n",
        "    ])\n",
        "    return tf\n",
        "\n",
        "\n",
        "def build_dtm(corpus: List[str]) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    we reuse what we implemented in previous tutorial\n",
        "    :param corpus:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    # build vocabulary - use nested list comprehension, set, and list\n",
        "    words = [\n",
        "        word\n",
        "        for doc in corpus\n",
        "        for word in doc.split(\" \")\n",
        "    ]\n",
        "    vocab = list(set(words))\n",
        "\n",
        "    # populate dtm, ith a nested for loop\n",
        "    dtm = [\n",
        "           [tf(term, doc) for term in vocab]  # row\n",
        "           for doc in corpus\n",
        "    ]\n",
        "\n",
        "    # return dtm as a pandas dataframe\n",
        "    dtm = pd.DataFrame(data=dtm, columns=vocab)\n",
        "    return dtm\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5888fENLIQqX"
      },
      "source": [
        "# complete this function\n",
        "def idf(term: str, corpus: List[str]) -> float:\n",
        "    ### TODO 1 ###\n",
        "    # idf = log(n / (1 + df))\n",
        "    n = len(corpus)\n",
        "    # df = term이 출현하는 문서의 개수.\n",
        "    df =  sum([\n",
        "          term in doc.split(\" \")  # T F\n",
        "          for doc in corpus\n",
        "    ])\n",
        "    idf = log(n / (1 + df))\n",
        "    ##############\n",
        "    return idf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meuOpD_KNNpP",
        "outputId": "813fcfde-4779-4504-f1c7-665b9c8d2360"
      },
      "source": [
        "print(idf(\"this\", CORPUS))\n",
        "print(idf(\"eubin\", CORPUS))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-0.1823215567939546\n",
            "1.6094379124341003\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZ4-x2kMJsnl"
      },
      "source": [
        "def build_dtm_with_tfidf(corpus: List[str]) -> pd.DataFrame:\n",
        "    # access the columns with df.columns\n",
        "    # multiply idfs to each row with numpy's broadcast mul\n",
        "    dtm = build_dtm(corpus) # tf <- (non-binary dtm)\n",
        "    ### TODO 2 ####\n",
        "    # reuse dtm to build dtm_tfidf\n",
        "    # use dtm.columns, idf, np.array(), dtm.to_numpy() and broadcast multiplication\n",
        "    idfs: List[float] = [\n",
        "                         idf(term, corpus)\n",
        "                         for term in dtm.columns\n",
        "    ]\n",
        "    dtm_tfidf: List[List[float]] = dtm.to_numpy() *   # 리스트, 혹은 넘파이 배열\n",
        "    ############### \n",
        "    return pd.DataFrame(data=dtm_tfidf, columns=dtm.columns)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rB_5uAIrKPqf",
        "outputId": "ad0cbc8a-cb69-4e6f-f390-952d0aabb372"
      },
      "source": [
        "# build dtm, and one with  \n",
        "dtm = build_dtm(CORPUS)\n",
        "dtm_tfidf = build_dtm_with_tfidf(CORPUS)\n",
        "print(dtm)\n",
        "print(dtm_tfidf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   document  first  the  third  is  and  second  this\n",
            "0         1      1    1      0   2    0       0     1\n",
            "1         1      1    1      0   2    0       0     1\n",
            "2         1      0    1      0   2    0       1     1\n",
            "3         1      0    1      1   2    1       0     1\n",
            "4         1      1    1      0   2    0       0     1\n",
            "   document     first       the     third        is       and    second  \\\n",
            "0 -0.182322  0.223144 -0.182322  0.000000 -0.364643  0.000000  0.000000   \n",
            "1 -0.182322  0.223144 -0.182322  0.000000 -0.364643  0.000000  0.000000   \n",
            "2 -0.182322  0.000000 -0.182322  0.000000 -0.364643  0.000000  0.916291   \n",
            "3 -0.182322  0.000000 -0.182322  0.916291 -0.364643  0.916291  0.000000   \n",
            "4 -0.182322  0.223144 -0.182322  0.000000 -0.364643  0.000000  0.000000   \n",
            "\n",
            "       this  \n",
            "0 -0.182322  \n",
            "1 -0.182322  \n",
            "2 -0.182322  \n",
            "3 -0.182322  \n",
            "4 -0.182322  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4oAQVQquMV2G"
      },
      "source": [
        "다음과 같은 결과가 나와야 합니다 (단어의 순서는 달라도 괜찮습니다):\n",
        "```\n",
        "   the  and  third  this  is  first  document  second\n",
        "0    1    0      0     1   2      1         1       0\n",
        "1    1    0      0     1   2      1         1       0\n",
        "2    1    0      0     1   2      0         1       1\n",
        "3    1    1      1     1   2      0         1       0\n",
        "4    1    0      0     1   2      1         1       0\n",
        "        the       and     third      this        is     first  document  \\\n",
        "0 -0.182322  0.000000  0.000000 -0.182322 -0.364643  0.223144 -0.182322   \n",
        "1 -0.182322  0.000000  0.000000 -0.182322 -0.364643  0.223144 -0.182322   \n",
        "2 -0.182322  0.000000  0.000000 -0.182322 -0.364643  0.000000 -0.182322   \n",
        "3 -0.182322  0.916291  0.916291 -0.182322 -0.364643  0.000000 -0.182322   \n",
        "4 -0.182322  0.000000  0.000000 -0.182322 -0.364643  0.223144 -0.182322   \n",
        "\n",
        "     second  \n",
        "0  0.000000  \n",
        "1  0.000000  \n",
        "2  0.916291  \n",
        "3  0.000000  \n",
        "4  0.000000  \n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSEEqll0Kp--"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SsHSXRkKTLK",
        "outputId": "36b2607a-1633-4cfb-ca8a-430acc50b37e"
      },
      "source": [
        "# compare the two\n",
        "print(cosine_similarity(dtm.to_numpy(), dtm.to_numpy()))\n",
        "print(cosine_similarity(dtm_tfidf.to_numpy(), dtm_tfidf.to_numpy()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1.         1.         0.875      0.82495791 1.        ]\n",
            " [1.         1.         0.875      0.82495791 1.        ]\n",
            " [0.875      0.875      1.         0.82495791 0.875     ]\n",
            " [0.82495791 0.82495791 0.82495791 1.         0.82495791]\n",
            " [1.         1.         0.875      0.82495791 1.        ]]\n",
            "[[1.         1.         0.4227912  0.31662902 1.        ]\n",
            " [1.         1.         0.4227912  0.31662902 1.        ]\n",
            " [0.4227912  0.4227912  1.         0.16251445 0.4227912 ]\n",
            " [0.31662902 0.31662902 0.16251445 1.         0.31662902]\n",
            " [1.         1.         0.4227912  0.31662902 1.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzdJrp3mMfPg"
      },
      "source": [
        "다음과 같은 결과가 나와야 합니다:\n",
        "```\n",
        "[[1.         1.         0.875      0.82495791 1.        ]\n",
        " [1.         1.         0.875      0.82495791 1.        ]\n",
        " [0.875      0.875      1.         0.82495791 0.875     ]\n",
        " [0.82495791 0.82495791 0.82495791 1.         0.82495791]\n",
        " [1.         1.         0.875      0.82495791 1.        ]]\n",
        "[[1.         1.         0.4227912  0.31662902 1.        ]\n",
        " [1.         1.         0.4227912  0.31662902 1.        ]\n",
        " [0.4227912  0.4227912  1.         0.16251445 0.4227912 ]\n",
        " [0.31662902 0.31662902 0.16251445 1.         0.31662902]\n",
        " [1.         1.         0.4227912  0.31662902 1.        ]]\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eg2616UaMrg6"
      },
      "source": [
        "## 다음의 질문에 답해주세요!\n",
        "\n",
        "> `dtm`으로 구한 유사도 행렬 대비, `dtm_tfidf`로 구한 유사도 행렬은 어떤 점이 개선되었나요? 그 이유는?\n",
        "\n",
        "> `dtm_tfidf`로도 해결할수 없는 문제를 발견할 수 있나요?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEGqECWqKo50"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
